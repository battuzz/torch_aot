{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/battuzz/torch_aot/blob/main/TorchAOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "# AOT Compilation of torch models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install latest version of pytorch (CPU)"
      ],
      "metadata": {
        "id": "BNv2cMSKrsLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCULUZZhodIC",
        "outputId": "1264525e-40d7-4385-fc0c-ad67ad435e66"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.1+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.1+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.7.1+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cmake"
      ],
      "metadata": {
        "id": "PaaK3bZcsTUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4e115e-a2a8-48a8-f050-a9ce823542dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (3.31.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "yNEB3fsosaDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "torch.set_default_dtype(torch.float64)   # Change this default data type that is the one used by the model computations. The C++ interface will always be float64"
      ],
      "metadata": {
        "id": "jCsYgJ7yzI4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8a85eb-c0bb-492a-f01b-8a79a16d31c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.1+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nma_JWh-W-IF"
      },
      "source": [
        "## Define models\n",
        "\n",
        "The models we chose are:\n",
        "- a very basic MLP with 3 layers\n",
        "- a simple Gaussian Process posterior with squared exponential kernel\n",
        "\n",
        "We use float64 as a default data type for the interface. However, we could also cast down to float32 to do computations and then cast the results back to float64 to gain some performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_INPUTS = 5\n",
        "NUM_OUTPUTS = 7\n",
        "NUM_INDUCING_POINTS = 350\n",
        "\n",
        "class ModelNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(NUM_INPUTS, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 128)\n",
        "        self.fc3 = torch.nn.Linear(128, NUM_OUTPUTS)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def squared_distance(x1, x2):\n",
        "    return (\n",
        "        torch.sum(x1**2, dim=1, keepdim=True)\n",
        "        + torch.sum(x2**2, dim=1)\n",
        "        - 2 * torch.mm(x1, x2.t())\n",
        "    )\n",
        "\n",
        "\n",
        "def rbf_kernel(x1, x2, lengthscale=1.0):\n",
        "    dist = squared_distance(x1 / lengthscale, x2 / lengthscale)\n",
        "    return torch.exp(-0.5 * dist)\n",
        "\n",
        "class ModelGPPosterior(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lengthscales = torch.nn.Parameter(torch.randn(NUM_INPUTS))\n",
        "        self.inducing_points = torch.nn.Parameter(\n",
        "        torch.randn(NUM_INDUCING_POINTS, NUM_INPUTS)\n",
        "        )\n",
        "        self.alpha = torch.nn.Parameter(torch.randn(NUM_INDUCING_POINTS, NUM_OUTPUTS))\n",
        "\n",
        "    def forward(self, x):\n",
        "        Kuf = rbf_kernel(x, self.inducing_points, self.lengthscales)\n",
        "        mean = Kuf @ self.alpha\n",
        "        return mean\n",
        "\n",
        "\n",
        "class CastToFloat64Wrapper(torch.nn.Module):\n",
        "    def __init__(self, inner_model : torch.nn.Module):\n",
        "        super().__init__()\n",
        "        self.model_ = inner_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_default_dtype = x.type(torch.get_default_dtype())\n",
        "        result = self.model_(x_default_dtype)\n",
        "        result_f64 = result.type(torch.float64)\n",
        "\n",
        "        return result_f64"
      ],
      "metadata": {
        "id": "JFylcD5CzD7L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train models with random data"
      ],
      "metadata": {
        "id": "Acc37j9q0Qpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_random_data(model):\n",
        "    X = torch.randn(1000, NUM_INPUTS).type(torch.float64)\n",
        "    y = torch.randn(1000, NUM_OUTPUTS).type(torch.float64)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    for epoch in range(30):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)\n",
        "        loss = torch.nn.functional.mse_loss(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "model_nn = CastToFloat64Wrapper(ModelNN())\n",
        "model_gp = CastToFloat64Wrapper(ModelGPPosterior())\n",
        "train_with_random_data(model_nn)\n",
        "train_with_random_data(model_gp)"
      ],
      "metadata": {
        "id": "dgwXxdZAzvSP",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0a650e-efb8-4287-d561-0fa3b576d595"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9978238012071641\n",
            "Epoch 2, Loss: 0.9965290112781162\n",
            "Epoch 3, Loss: 0.9952749213191149\n",
            "Epoch 4, Loss: 0.994061126066982\n",
            "Epoch 5, Loss: 0.9928870313537529\n",
            "Epoch 6, Loss: 0.9917540233458468\n",
            "Epoch 7, Loss: 0.9906601361048546\n",
            "Epoch 8, Loss: 0.9896044033370593\n",
            "Epoch 9, Loss: 0.9885861983119293\n",
            "Epoch 10, Loss: 0.987604158883998\n",
            "Epoch 11, Loss: 0.9866569744713525\n",
            "Epoch 12, Loss: 0.9857445739751902\n",
            "Epoch 13, Loss: 0.98486760698659\n",
            "Epoch 14, Loss: 0.9840230932904375\n",
            "Epoch 15, Loss: 0.9832090206324187\n",
            "Epoch 16, Loss: 0.9824244705443933\n",
            "Epoch 17, Loss: 0.9816697725218735\n",
            "Epoch 18, Loss: 0.9809429698205399\n",
            "Epoch 19, Loss: 0.9802439656227822\n",
            "Epoch 20, Loss: 0.9795702244311616\n",
            "Epoch 21, Loss: 0.9789185884869569\n",
            "Epoch 22, Loss: 0.978288564934835\n",
            "Epoch 23, Loss: 0.9776791901626033\n",
            "Epoch 24, Loss: 0.9770892672377227\n",
            "Epoch 25, Loss: 0.9765203592998056\n",
            "Epoch 26, Loss: 0.9759698374167334\n",
            "Epoch 27, Loss: 0.975436906603212\n",
            "Epoch 28, Loss: 0.9749198646298654\n",
            "Epoch 29, Loss: 0.9744185353810849\n",
            "Epoch 30, Loss: 0.9739311713188549\n",
            "Epoch 1, Loss: 0.9961003369024247\n",
            "Epoch 2, Loss: 0.9960855928531972\n",
            "Epoch 3, Loss: 0.9960708588150999\n",
            "Epoch 4, Loss: 0.9960561351902788\n",
            "Epoch 5, Loss: 0.9960414223018175\n",
            "Epoch 6, Loss: 0.9960267203693524\n",
            "Epoch 7, Loss: 0.9960120295081502\n",
            "Epoch 8, Loss: 0.9959973497372857\n",
            "Epoch 9, Loss: 0.9959826809843275\n",
            "Epoch 10, Loss: 0.9959680230850824\n",
            "Epoch 11, Loss: 0.9959533757809351\n",
            "Epoch 12, Loss: 0.9959387387171404\n",
            "Epoch 13, Loss: 0.9959241114419456\n",
            "Epoch 14, Loss: 0.9959094934055032\n",
            "Epoch 15, Loss: 0.9958948839583882\n",
            "Epoch 16, Loss: 0.9958802823499047\n",
            "Epoch 17, Loss: 0.9958656877265998\n",
            "Epoch 18, Loss: 0.9958510991316781\n",
            "Epoch 19, Loss: 0.9958365155059273\n",
            "Epoch 20, Loss: 0.9958219356903018\n",
            "Epoch 21, Loss: 0.9958073584297383\n",
            "Epoch 22, Loss: 0.9957927823774649\n",
            "Epoch 23, Loss: 0.9957782060990988\n",
            "Epoch 24, Loss: 0.9957636280761489\n",
            "Epoch 25, Loss: 0.9957490467088738\n",
            "Epoch 26, Loss: 0.9957344603187069\n",
            "Epoch 27, Loss: 0.9957198671505593\n",
            "Epoch 28, Loss: 0.99570526537533\n",
            "Epoch 29, Loss: 0.9956906530929301\n",
            "Epoch 30, Loss: 0.9956760283360799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export models"
      ],
      "metadata": {
        "id": "3v_ChXeJD8PO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = torch.randn((1, NUM_INPUTS)).type(torch.float64)\n",
        "\n",
        "# Export NN\n",
        "model_nn.eval()\n",
        "\n",
        "exported = torch.export.export(model_nn, (example_input,))\n",
        "torch._inductor.aoti_compile_and_package(\n",
        "    exported,\n",
        "    package_path=\"model_nn.pt2\",\n",
        ")\n",
        "with open(\"model_nn_inputs_shape.txt\", \"w\") as f:\n",
        "    f.write(\n",
        "        f\"{len(example_input.shape)} {' '.join(map(str, example_input.shape))}\"\n",
        "    )\n",
        "\n",
        "model_gp.eval()\n",
        "\n",
        "exported = torch.export.export(model_gp, (example_input,))\n",
        "torch._inductor.aoti_compile_and_package(\n",
        "    exported,\n",
        "    package_path=\"model_gp.pt2\",\n",
        ")\n",
        "with open(\"model_gp_inputs_shape.txt\", \"w\") as f:\n",
        "    f.write(\n",
        "        f\"{len(example_input.shape)} {' '.join(map(str, example_input.shape))}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "3cIXcaWA1cCk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write artefacts used in compilation\n",
        "\n",
        "In particular we'll need:\n",
        "- A CMakeLists.txt\n",
        "- The inference.cpp code that loads and benchmarks the model\n",
        "- A build script that compiles\n"
      ],
      "metadata": {
        "id": "0TtHi_2GEa5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmake_contents = \"\"\"cmake_minimum_required(VERSION 3.18 FATAL_ERROR)\n",
        "project(aoti_example)\n",
        "\n",
        "find_package(Torch REQUIRED)\n",
        "\n",
        "add_executable(aoti_example inference.cpp)\n",
        "\n",
        "target_link_libraries(aoti_example \"${TORCH_LIBRARIES}\")\n",
        "set_property(TARGET aoti_example PROPERTY CXX_STANDARD 17)\n",
        "\"\"\"\n",
        "with open('CMakeLists.txt', 'w') as f:\n",
        "    f.write(cmake_contents)"
      ],
      "metadata": {
        "id": "DTHMpZyM7mT7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_contents = \"\"\"export CMAKE_PREFIX_PATH=/usr/local/lib/python3.11/dist-packages/torch/share/cmake\n",
        "export TORCHINDUCTOR_FREEZING=1\n",
        "\n",
        "\n",
        "rm -rf build\n",
        "mkdir build\n",
        "cmake -B build .\n",
        "cmake --build build --config Release\n",
        "\"\"\"\n",
        "with open('build.sh', 'w') as f:\n",
        "    f.write(build_contents)"
      ],
      "metadata": {
        "id": "XbFtCu1t79Sx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x ./build.sh"
      ],
      "metadata": {
        "id": "viy_pWo021NY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_content = \"\"\"#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <fstream>\n",
        "\n",
        "#include <torch/torch.h>\n",
        "#include <torch/csrc/inductor/aoti_package/model_package_loader.h>\n",
        "\n",
        "using namespace std::chrono;\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "\n",
        "    if (argc < 3) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" <model.pt2> <inputs.txt>\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Load input\n",
        "    std::ifstream input_file{argv[2]};\n",
        "    if (!input_file) {\n",
        "        std::cerr << \"Error opening input file: \" << argv[2] << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "    int num_dims {};\n",
        "    input_file >> num_dims;\n",
        "\n",
        "    std::vector<int64_t> input_dims{};\n",
        "    for (int i = 0; i < num_dims; ++i) {\n",
        "        int64_t dim_size;\n",
        "        input_file >> dim_size;\n",
        "        input_dims.push_back(dim_size);\n",
        "    }\n",
        "\n",
        "    input_file.close();\n",
        "\n",
        "    torch::Tensor input = torch::randn(input_dims, torch::dtype(torch::kFloat64));\n",
        "    std::vector<torch::Tensor> inputs { input };\n",
        "\n",
        "    c10::InferenceMode mode;\n",
        "    torch::inductor::AOTIModelPackageLoader loader(argv[1], \"model\", false);\n",
        "\n",
        "    // Warmup\n",
        "    std::vector<torch::Tensor> outputs;\n",
        "    for (int i = 0; i < 1000; i++) {\n",
        "        outputs = loader.run(inputs);\n",
        "    }\n",
        "\n",
        "    // Benchmark\n",
        "    auto start_time = std::chrono::high_resolution_clock::now();\n",
        "    for (int i = 0; i < 1000; i++) {\n",
        "        outputs = loader.run(inputs);\n",
        "    }\n",
        "    auto end_time = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    auto elapsed = duration_cast<microseconds>(end_time - start_time);\n",
        "    std::cout << \"Average inference time over 1000 runs: \"\n",
        "              << (elapsed.count() / 1000) << \" us\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with open('inference.cpp', 'w') as f:\n",
        "    f.write(cpp_content)"
      ],
      "metadata": {
        "id": "1kFbKixS8Ixw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ."
      ],
      "metadata": {
        "id": "W-8Z-w542_to",
        "outputId": "fe589d31-946d-4dea-bb89-ebce30181b6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build\t\tinference.cpp\t\t   model_nn_inputs_shape.txt\n",
            "build.sh\tmodel_gp_inputs_shape.txt  model_nn.pt2\n",
            "CMakeLists.txt\tmodel_gp.pt2\t\t   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ],
      "metadata": {
        "id": "3GIRXUtzEzdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./build.sh"
      ],
      "metadata": {
        "id": "iw3MHqnR3C9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62130874-b2a8-4bac-fb07-6bd554e3846f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[33mCMake Warning at /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22 (message):\n",
            "  static library kineto_LIBRARY-NOTFOUND not found.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:125 (append_torchlib_if_found)\n",
            "  CMakeLists.txt:4 (find_package)\n",
            "\n",
            "\u001b[0m\n",
            "-- Found Torch: /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch.so\n",
            "-- Configuring done (0.5s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/build\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/aoti_example.dir/inference.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable aoti_example\u001b[0m\n",
            "[100%] Built target aoti_example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the benchmark"
      ],
      "metadata": {
        "id": "IkIUzoV7E54b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./build/aoti_example model_nn.pt2 model_nn_inputs_shape.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_w_dKYy9Ai5",
        "outputId": "f2d31ccd-3e39-407c-8bd2-f30e5e85e8dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average inference time over 1000 runs: 14 us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./build/aoti_example model_gp.pt2 model_gp_inputs_shape.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duk06KFpswEd",
        "outputId": "77264ac4-061a-4b1c-bdd3-55810512ea84"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average inference time over 1000 runs: 18 us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Empirical results\n",
        "\n",
        "On our benchmarks on a normal laptop we measured the following (time is in us):\n",
        "\n",
        "| method | MLP f64 | MLP f32  | GP f64  | GP f32  |\n",
        "|---|---|---|---|---|\n",
        "| AOT Inductor (torch)  | 11  | 12  | 10  | 11  |\n",
        "| ONNX runtime (torch)  | 11  | 5  | 12  | 8  |\n",
        "| Tensorflow AOT  | 3  | -  | 7  | -  |\n"
      ],
      "metadata": {
        "id": "F0-LJvKWL0rT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try to export with derivatives / jacobian\n",
        "\n",
        "Exporting derivatives fails because of unsupported operations"
      ],
      "metadata": {
        "id": "a-jC-LxtvbYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWithJacobian(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model_ = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        dy = torch.autograd.functional.jacobian(self.model_, x, create_graph=True)\n",
        "        return dy\n",
        "\n",
        "\n",
        "class ModelWithGrads(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model_ = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.model_(x)\n",
        "        dy = torch.autograd.grad(y, x, retain_graph=True, create_graph=True, )\n",
        "        return dy\n"
      ],
      "metadata": {
        "id": "AUUSTj961TlY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = ModelWithJacobian(model_nn)\n",
        "\n",
        "m.eval()\n",
        "\n",
        "exported = torch.export.export(m, (example_input,))\n",
        "torch._inductor.aoti_compile_and_package(\n",
        "    exported,\n",
        "    package_path=\"model_grads.pt2\",\n",
        ")"
      ],
      "metadata": {
        "id": "goslY-Lh3XSg",
        "outputId": "a0daa19c-e4a5-4986-cd6f-d79366b238c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Unsupported",
          "evalue": "Failed to convert args/kwargs to proxy\n  Explanation: Missing `as_proxy()` implementation for some arg/kwarg.\n\n\n  Developer debug context: call_function args: NNModuleVariable() TensorVariable() ConstantVariable(bool: True)\n\n\nfrom user code:\n   File \"/tmp/ipython-input-17-2830246847.py\", line 7, in forward\n    dy = torch.autograd.functional.jacobian(self.model_, x, create_graph=True)\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnsupported\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-3032901871.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexample_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m torch._inductor.aoti_compile_and_package(\n\u001b[1;32m      7\u001b[0m     \u001b[0mexported\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;34m\"using `TS2EPConverter(mod, args, kwargs).convert()` instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         )\n\u001b[0;32m--> 360\u001b[0;31m     return _export(\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 )\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0m_EXPORT_FLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m             \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             log_export_usage(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/exported_program.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0munset_fake_temporarily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, pre_dispatch, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace)\u001b[0m\n\u001b[1;32m   2118\u001b[0m     \u001b[0;31m# while internally it returns False UNLESS otherwise specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexport_training_ir_rollout_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m         ep = _export_for_training(\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 )\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0m_EXPORT_FLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m             \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             log_export_usage(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/exported_program.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0munset_fake_temporarily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_export_for_training\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[1;32m   1981\u001b[0m         )\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[0;32m-> 1983\u001b[0;31m     export_artifact = export_func(  # type: ignore[operator]\n\u001b[0m\u001b[1;32m   1984\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_strict_export_lower_to_aten_ir\u001b[0;34m(mod, args, kwargs, dynamic_shapes, preserve_module_call_signature, pre_dispatch, original_state_dict, orig_in_spec, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace, lower_to_aten_callback)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0mlower_to_aten_callback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m ) -> ExportArtifact:\n\u001b[0;32m-> 1352\u001b[0;31m     gm_torch_level = _export_to_torch_ir(\n\u001b[0m\u001b[1;32m   1353\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_export_to_torch_ir\u001b[0;34m(f, args, kwargs, dynamic_shapes, preserve_module_call_signature, disable_constraint_solver, allow_complex_guards_as_runtime_asserts, restore_fqn, _log_export_usage, same_signature)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 )\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ignore_backend_decomps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 gm_torch_level, _ = torch._dynamo.export(\n\u001b[0m\u001b[1;32m    741\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mdynamic_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_shapes\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0;31m# TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m                 \u001b[0mresult_traced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConstraintViolationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m                 \u001b[0mconstraint_violation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mShortenTraceback\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m                     \u001b[0;31m# Failures in the backend likely don't have useful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnsupported\u001b[0m: Failed to convert args/kwargs to proxy\n  Explanation: Missing `as_proxy()` implementation for some arg/kwarg.\n\n\n  Developer debug context: call_function args: NNModuleVariable() TensorVariable() ConstantVariable(bool: True)\n\n\nfrom user code:\n   File \"/tmp/ipython-input-17-2830246847.py\", line 7, in forward\n    dy = torch.autograd.functional.jacobian(self.model_, x, create_graph=True)\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = ModelWithGrads(model_nn)\n",
        "\n",
        "m.eval()\n",
        "\n",
        "exported = torch.export.export(m, (example_input,))\n",
        "torch._inductor.aoti_compile_and_package(\n",
        "    exported,\n",
        "    package_path=\"model_grads.pt2\",\n",
        ")"
      ],
      "metadata": {
        "id": "Alh6fP4k4hb6",
        "outputId": "c44d1edd-abc0-41ad-856d-aa7302d4cde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Unsupported",
          "evalue": "Attempted to call function marked as skipped\n  Explanation: Dynamo developers have intentionally marked that the function `grad` in file `/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py` should not be traced.\n  Hint: Avoid calling the function `grad`.\n  Hint: Remove the function `grad` or the file `/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py` from torch/_dynamo/trace_rules.py. More graph breaks may occur as a result of attempting to trace into the function.\n  Hint: Please file an issue to PyTorch.\n\n  Developer debug context: module: torch.autograd, qualname: grad, skip reason: <missing reason>\n\n\nfrom user code:\n   File \"/tmp/ipython-input-17-2830246847.py\", line 18, in forward\n    dy = torch.autograd.grad(y, x, retain_graph=True, create_graph=True, )\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnsupported\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-756340534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexample_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m torch._inductor.aoti_compile_and_package(\n\u001b[1;32m      7\u001b[0m     \u001b[0mexported\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;34m\"using `TS2EPConverter(mod, args, kwargs).convert()` instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         )\n\u001b[0;32m--> 360\u001b[0;31m     return _export(\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 )\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0m_EXPORT_FLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m             \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             log_export_usage(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/exported_program.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0munset_fake_temporarily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, pre_dispatch, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace)\u001b[0m\n\u001b[1;32m   2118\u001b[0m     \u001b[0;31m# while internally it returns False UNLESS otherwise specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexport_training_ir_rollout_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m         ep = _export_for_training(\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 )\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0m_EXPORT_FLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m             \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             log_export_usage(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/exported_program.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0munset_fake_temporarily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_export_for_training\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[1;32m   1981\u001b[0m         )\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[0;32m-> 1983\u001b[0;31m     export_artifact = export_func(  # type: ignore[operator]\n\u001b[0m\u001b[1;32m   1984\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_strict_export_lower_to_aten_ir\u001b[0;34m(mod, args, kwargs, dynamic_shapes, preserve_module_call_signature, pre_dispatch, original_state_dict, orig_in_spec, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace, lower_to_aten_callback)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0mlower_to_aten_callback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m ) -> ExportArtifact:\n\u001b[0;32m-> 1352\u001b[0;31m     gm_torch_level = _export_to_torch_ir(\n\u001b[0m\u001b[1;32m   1353\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_export_to_torch_ir\u001b[0;34m(f, args, kwargs, dynamic_shapes, preserve_module_call_signature, disable_constraint_solver, allow_complex_guards_as_runtime_asserts, restore_fqn, _log_export_usage, same_signature)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 )\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ignore_backend_decomps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 gm_torch_level, _ = torch._dynamo.export(\n\u001b[0m\u001b[1;32m    741\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mdynamic_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_shapes\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0;31m# TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m                 \u001b[0mresult_traced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConstraintViolationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m                 \u001b[0mconstraint_violation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mShortenTraceback\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m                     \u001b[0;31m# Failures in the backend likely don't have useful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnsupported\u001b[0m: Attempted to call function marked as skipped\n  Explanation: Dynamo developers have intentionally marked that the function `grad` in file `/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py` should not be traced.\n  Hint: Avoid calling the function `grad`.\n  Hint: Remove the function `grad` or the file `/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py` from torch/_dynamo/trace_rules.py. More graph breaks may occur as a result of attempting to trace into the function.\n  Hint: Please file an issue to PyTorch.\n\n  Developer debug context: module: torch.autograd, qualname: grad, skip reason: <missing reason>\n\n\nfrom user code:\n   File \"/tmp/ipython-input-17-2830246847.py\", line 18, in forward\n    dy = torch.autograd.grad(y, x, retain_graph=True, create_graph=True, )\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vtBuMqO3Zmb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}