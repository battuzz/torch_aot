{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/battuzz/torch_aot/blob/main/TorchAOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "# AOT Compilation of torch models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "jCsYgJ7yzI4E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nma_JWh-W-IF"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_INPUTS = 5\n",
        "NUM_OUTPUTS = 7\n",
        "NUM_INDUCING_POINTS = 350\n",
        "\n",
        "class ModelNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(NUM_INPUTS, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 128)\n",
        "        self.fc3 = torch.nn.Linear(128, NUM_OUTPUTS)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def squared_distance(x1, x2):\n",
        "    return (\n",
        "        torch.sum(x1**2, dim=1, keepdim=True)\n",
        "        + torch.sum(x2**2, dim=1)\n",
        "        - 2 * torch.mm(x1, x2.t())\n",
        "    )\n",
        "\n",
        "\n",
        "def rbf_kernel(x1, x2, lengthscale=1.0):\n",
        "    dist = squared_distance(x1 / lengthscale, x2 / lengthscale)\n",
        "    return torch.exp(-0.5 * dist)\n",
        "\n",
        "class ModelGPPosterior(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lengthscales = torch.nn.Parameter(torch.randn(NUM_INPUTS))\n",
        "        self.inducing_points = torch.nn.Parameter(\n",
        "        torch.randn(NUM_INDUCING_POINTS, NUM_INPUTS)\n",
        "        )\n",
        "        self.alpha = torch.nn.Parameter(torch.randn(NUM_INDUCING_POINTS, NUM_OUTPUTS))\n",
        "\n",
        "    def forward(self, x):\n",
        "        Kuf = rbf_kernel(x, self.inducing_points, self.lengthscales)\n",
        "        mean = Kuf @ self.alpha\n",
        "        return mean"
      ],
      "metadata": {
        "id": "JFylcD5CzD7L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Acc37j9q0Qpb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_random_data(model):\n",
        "    X = torch.randn(1000, NUM_INPUTS)\n",
        "    y = torch.randn(1000, NUM_OUTPUTS)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    for epoch in range(30):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)\n",
        "        loss = torch.nn.functional.mse_loss(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "dgwXxdZAzvSP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn = ModelNN()\n",
        "model_gp = ModelGPPosterior()\n",
        "train_with_random_data(model_nn)\n",
        "train_with_random_data(model_gp)"
      ],
      "metadata": {
        "id": "AgZin0RS1EjE",
        "outputId": "c0d1cfd1-2f5d-4b7e-d962-b23223c741b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0243384838104248\n",
            "Epoch 2, Loss: 1.0232675075531006\n",
            "Epoch 3, Loss: 1.0222439765930176\n",
            "Epoch 4, Loss: 1.0212637186050415\n",
            "Epoch 5, Loss: 1.0203267335891724\n",
            "Epoch 6, Loss: 1.0194319486618042\n",
            "Epoch 7, Loss: 1.0185813903808594\n",
            "Epoch 8, Loss: 1.0177745819091797\n",
            "Epoch 9, Loss: 1.017008900642395\n",
            "Epoch 10, Loss: 1.0162802934646606\n",
            "Epoch 11, Loss: 1.0155872106552124\n",
            "Epoch 12, Loss: 1.0149301290512085\n",
            "Epoch 13, Loss: 1.014306902885437\n",
            "Epoch 14, Loss: 1.0137146711349487\n",
            "Epoch 15, Loss: 1.0131503343582153\n",
            "Epoch 16, Loss: 1.0126134157180786\n",
            "Epoch 17, Loss: 1.0121012926101685\n",
            "Epoch 18, Loss: 1.0116132497787476\n",
            "Epoch 19, Loss: 1.0111464262008667\n",
            "Epoch 20, Loss: 1.0106998682022095\n",
            "Epoch 21, Loss: 1.0102720260620117\n",
            "Epoch 22, Loss: 1.0098613500595093\n",
            "Epoch 23, Loss: 1.0094648599624634\n",
            "Epoch 24, Loss: 1.009081482887268\n",
            "Epoch 25, Loss: 1.0087114572525024\n",
            "Epoch 26, Loss: 1.00835120677948\n",
            "Epoch 27, Loss: 1.007997989654541\n",
            "Epoch 28, Loss: 1.0076525211334229\n",
            "Epoch 29, Loss: 1.007313847541809\n",
            "Epoch 30, Loss: 1.006981372833252\n",
            "Epoch 1, Loss: 1.3157447576522827\n",
            "Epoch 2, Loss: 1.3149312734603882\n",
            "Epoch 3, Loss: 1.3141193389892578\n",
            "Epoch 4, Loss: 1.313308835029602\n",
            "Epoch 5, Loss: 1.312499761581421\n",
            "Epoch 6, Loss: 1.3116923570632935\n",
            "Epoch 7, Loss: 1.3108867406845093\n",
            "Epoch 8, Loss: 1.3100824356079102\n",
            "Epoch 9, Loss: 1.3092801570892334\n",
            "Epoch 10, Loss: 1.3084791898727417\n",
            "Epoch 11, Loss: 1.3076801300048828\n",
            "Epoch 12, Loss: 1.306882381439209\n",
            "Epoch 13, Loss: 1.306086778640747\n",
            "Epoch 14, Loss: 1.3052928447723389\n",
            "Epoch 15, Loss: 1.3045004606246948\n",
            "Epoch 16, Loss: 1.303709864616394\n",
            "Epoch 17, Loss: 1.3029210567474365\n",
            "Epoch 18, Loss: 1.3021339178085327\n",
            "Epoch 19, Loss: 1.3013488054275513\n",
            "Epoch 20, Loss: 1.3005656003952026\n",
            "Epoch 21, Loss: 1.2997839450836182\n",
            "Epoch 22, Loss: 1.299004316329956\n",
            "Epoch 23, Loss: 1.298226237297058\n",
            "Epoch 24, Loss: 1.2974501848220825\n",
            "Epoch 25, Loss: 1.2966760396957397\n",
            "Epoch 26, Loss: 1.2959036827087402\n",
            "Epoch 27, Loss: 1.295133113861084\n",
            "Epoch 28, Loss: 1.29436457157135\n",
            "Epoch 29, Loss: 1.2935978174209595\n",
            "Epoch 30, Loss: 1.292832851409912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = torch.randn((1, NUM_INPUTS))\n",
        "model_nn.eval()\n",
        "\n",
        "exported = torch.export.export(model_nn, (example_input,))\n",
        "torch._inductor.aoti_compile_and_package(\n",
        "    exported,\n",
        "    package_path=\"model_nn.pt2\",\n",
        ")"
      ],
      "metadata": {
        "id": "3cIXcaWA1cCk",
        "outputId": "7f95b6d2-0024-47df-b034-c87dcb2517c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_nn.pt2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cmake"
      ],
      "metadata": {
        "id": "TfX5d4jH1qMl",
        "outputId": "b73a7e97-7da4-4924-a01c-05851ee6f8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (3.31.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmake_contents = \"\"\"cmake_minimum_required(VERSION 3.18 FATAL_ERROR)\n",
        "project(aoti_example)\n",
        "\n",
        "find_package(Torch REQUIRED)\n",
        "\n",
        "add_executable(aoti_example inference.cpp)\n",
        "\n",
        "target_link_libraries(aoti_example \"${TORCH_LIBRARIES}\")\n",
        "set_property(TARGET aoti_example PROPERTY CXX_STANDARD 17)\n",
        "\"\"\"\n",
        "with open('CmakeLists.txt', 'w') as f:\n",
        "    f.write(cmake_contents)"
      ],
      "metadata": {
        "id": "DTHMpZyM7mT7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_contents = \"\"\"export CMAKE_PREFIX_PATH=/home/abattistello/.venv/lib/python3.11/site-packages/torch/share/cmake\n",
        "export TORCHINDUCTOR_FREEZING=1\n",
        "\n",
        "\n",
        "rm -rf build\n",
        "mkdir build\n",
        "cmake -B build .\n",
        "cmake --build build --config Release\n",
        "\"\"\"\n",
        "with open('build.sh', 'w') as f:\n",
        "    f.write(build_contents)"
      ],
      "metadata": {
        "id": "XbFtCu1t79Sx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x ./build.sh"
      ],
      "metadata": {
        "id": "viy_pWo021NY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_content = \"\"\"#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <fstream>\n",
        "\n",
        "#include <torch/torch.h>\n",
        "#include <torch/csrc/inductor/aoti_package/model_package_loader.h>\n",
        "\n",
        "using namespace std::chrono;\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "\n",
        "    if (argc < 3) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" <model.pt2> <inputs.txt>\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Load input\n",
        "    std::ifstream input_file{argv[2]};\n",
        "    if (!input_file) {\n",
        "        std::cerr << \"Error opening input file: \" << argv[2] << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "    int num_dims {};\n",
        "    input_file >> num_dims;\n",
        "\n",
        "    std::vector<int64_t> input_dims{};\n",
        "    for (int i = 0; i < num_dims; ++i) {\n",
        "        int64_t dim_size;\n",
        "        input_file >> dim_size;\n",
        "        input_dims.push_back(dim_size);\n",
        "    }\n",
        "\n",
        "    input_file.close();\n",
        "\n",
        "    // auto arrayRef = c10::makeArrayRef(input_dims);\n",
        "    torch::Tensor input = torch::randn(input_dims, torch::dtype(torch::kFloat64));\n",
        "    std::vector<torch::Tensor> inputs { input };\n",
        "\n",
        "    c10::InferenceMode mode;\n",
        "    torch::inductor::AOTIModelPackageLoader loader(argv[1], \"model\", false);\n",
        "\n",
        "\n",
        "    // std::vector<torch::Tensor> inputs = {torch::randn({1, 2}, torch::dtype(torch::kFloat64))};\n",
        "\n",
        "    // Warmup\n",
        "    std::vector<torch::Tensor> outputs;\n",
        "    for (int i = 0; i < 1000; i++) {\n",
        "        outputs = loader.run(inputs);\n",
        "    }\n",
        "\n",
        "    // Benchmark\n",
        "    auto start_time = std::chrono::high_resolution_clock::now();\n",
        "    for (int i = 0; i < 1000; i++) {\n",
        "        outputs = loader.run(inputs);\n",
        "    }\n",
        "    auto end_time = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    auto elapsed = duration_cast<microseconds>(end_time - start_time);\n",
        "    std::cout << \"Average inference time over 1000 runs: \"\n",
        "              << (elapsed.count() / 1000) << \" us\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1kFbKixS8Ixw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./build.sh"
      ],
      "metadata": {
        "id": "W-8Z-w542_to",
        "outputId": "65ece5cb-4cef-4e03-8171-2ae1b7edabbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./build.sh: line 3: $'\\r': command not found\n",
            "./build.sh: line 4: $'\\r': command not found\n",
            "\u001b[33mCMake Warning:\n",
            "  Ignoring extra path from command line:\n",
            "\n",
            "   \".\r\"\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[31mCMake Error at CMakeLists.txt:4 (find_package):\n",
            "  By not providing \"FindTorch.cmake\" in CMAKE_MODULE_PATH this project has\n",
            "  asked CMake to find a package configuration file provided by \"Torch\", but\n",
            "  CMake did not find one.\n",
            "\n",
            "  Could not find a package configuration file provided by \"Torch\" with any of\n",
            "  the following names:\n",
            "\n",
            "    TorchConfig.cmake\n",
            "    torch-config.cmake\n",
            "\n",
            "  Add the installation prefix of \"Torch\" to CMAKE_PREFIX_PATH or set\n",
            "  \"Torch_DIR\" to a directory containing one of the above files.  If \"Torch\"\n",
            "  provides a separate development package or SDK, be sure it has been\n",
            "  installed.\n",
            "\n",
            "\u001b[0m\n",
            "-- Configuring incomplete, errors occurred!\n",
            "gmake: Makefile: No such file or directory\n",
            "gmake: *** No rule to make target 'Makefile'.  Stop.\n",
            "./build.sh: line 9: $'\\r': command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iw3MHqnR3C9T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}