{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/battuzz/torch_aot/blob/main/TorchAOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "# AOT Compilation of torch models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install latest version of pytorch (CPU)"
      ],
      "metadata": {
        "id": "BNv2cMSKrsLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pCULUZZhodIC",
        "outputId": "95730208-b627-43ba-b00b-1ce03f374c35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.1+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.1+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.7.1+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: sympy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cmake"
      ],
      "metadata": {
        "id": "PaaK3bZcsTUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "yNEB3fsosaDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "torch.set_default_dtype(torch.float64)"
      ],
      "metadata": {
        "id": "jCsYgJ7yzI4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db022ab3-3033-4f67-97ef-be36f944698d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.1+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nma_JWh-W-IF"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_INPUTS = 5\n",
        "NUM_OUTPUTS = 7\n",
        "NUM_INDUCING_POINTS = 350\n",
        "\n",
        "class ModelNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(NUM_INPUTS, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 128)\n",
        "        self.fc3 = torch.nn.Linear(128, NUM_OUTPUTS)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def squared_distance(x1, x2):\n",
        "    return (\n",
        "        torch.sum(x1**2, dim=1, keepdim=True)\n",
        "        + torch.sum(x2**2, dim=1)\n",
        "        - 2 * torch.mm(x1, x2.t())\n",
        "    )\n",
        "\n",
        "\n",
        "def rbf_kernel(x1, x2, lengthscale=1.0):\n",
        "    dist = squared_distance(x1 / lengthscale, x2 / lengthscale)\n",
        "    return torch.exp(-0.5 * dist)\n",
        "\n",
        "class ModelGPPosterior(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lengthscales = torch.nn.Parameter(torch.randn(NUM_INPUTS))\n",
        "        self.inducing_points = torch.nn.Parameter(\n",
        "        torch.randn(NUM_INDUCING_POINTS, NUM_INPUTS)\n",
        "        )\n",
        "        self.alpha = torch.nn.Parameter(torch.randn(NUM_INDUCING_POINTS, NUM_OUTPUTS))\n",
        "\n",
        "    def forward(self, x):\n",
        "        Kuf = rbf_kernel(x, self.inducing_points, self.lengthscales)\n",
        "        mean = Kuf @ self.alpha\n",
        "        return mean"
      ],
      "metadata": {
        "id": "JFylcD5CzD7L"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Acc37j9q0Qpb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_random_data(model):\n",
        "    X = torch.randn(1000, NUM_INPUTS)\n",
        "    y = torch.randn(1000, NUM_OUTPUTS)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    for epoch in range(30):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)\n",
        "        loss = torch.nn.functional.mse_loss(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "dgwXxdZAzvSP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn = ModelNN()\n",
        "model_gp = ModelGPPosterior()\n",
        "train_with_random_data(model_nn)\n",
        "train_with_random_data(model_gp)"
      ],
      "metadata": {
        "id": "AgZin0RS1EjE",
        "outputId": "dde73c26-13bf-4367-e288-8b3ed3d1e7d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0249337383042418\n",
            "Epoch 2, Loss: 1.0240663061429183\n",
            "Epoch 3, Loss: 1.023237230116913\n",
            "Epoch 4, Loss: 1.0224466135230583\n",
            "Epoch 5, Loss: 1.0216944885337036\n",
            "Epoch 6, Loss: 1.0209787778836588\n",
            "Epoch 7, Loss: 1.0202930912333692\n",
            "Epoch 8, Loss: 1.0196385097524077\n",
            "Epoch 9, Loss: 1.0190139914511325\n",
            "Epoch 10, Loss: 1.018421251218499\n",
            "Epoch 11, Loss: 1.0178573037013714\n",
            "Epoch 12, Loss: 1.0173186258010265\n",
            "Epoch 13, Loss: 1.0168017457016565\n",
            "Epoch 14, Loss: 1.0163069628270254\n",
            "Epoch 15, Loss: 1.015832781810941\n",
            "Epoch 16, Loss: 1.0153746602166944\n",
            "Epoch 17, Loss: 1.0149334798490608\n",
            "Epoch 18, Loss: 1.0145104799240747\n",
            "Epoch 19, Loss: 1.0141028128256495\n",
            "Epoch 20, Loss: 1.013710964157435\n",
            "Epoch 21, Loss: 1.0133321824577843\n",
            "Epoch 22, Loss: 1.0129642900206837\n",
            "Epoch 23, Loss: 1.012606444883554\n",
            "Epoch 24, Loss: 1.0122576431917354\n",
            "Epoch 25, Loss: 1.011916529581065\n",
            "Epoch 26, Loss: 1.0115826434628437\n",
            "Epoch 27, Loss: 1.011255069098299\n",
            "Epoch 28, Loss: 1.0109339938948756\n",
            "Epoch 29, Loss: 1.0106186913272117\n",
            "Epoch 30, Loss: 1.010310085193367\n",
            "Epoch 1, Loss: 2.178877776819594\n",
            "Epoch 2, Loss: 2.176551374103407\n",
            "Epoch 3, Loss: 2.174229254215205\n",
            "Epoch 4, Loss: 2.171911483695698\n",
            "Epoch 5, Loss: 2.169598128072245\n",
            "Epoch 6, Loss: 2.1672892516099633\n",
            "Epoch 7, Loss: 2.1649849171226383\n",
            "Epoch 8, Loss: 2.1626851858014833\n",
            "Epoch 9, Loss: 2.160390117037657\n",
            "Epoch 10, Loss: 2.1580997683141856\n",
            "Epoch 11, Loss: 2.1558141951723924\n",
            "Epoch 12, Loss: 2.1535334511926045\n",
            "Epoch 13, Loss: 2.1512575879306977\n",
            "Epoch 14, Loss: 2.1489866548073806\n",
            "Epoch 15, Loss: 2.1467206989839007\n",
            "Epoch 16, Loss: 2.144459765252369\n",
            "Epoch 17, Loss: 2.1422038959514618\n",
            "Epoch 18, Loss: 2.1399531309086046\n",
            "Epoch 19, Loss: 2.13770750740785\n",
            "Epoch 20, Loss: 2.1354670601836427\n",
            "Epoch 21, Loss: 2.133231821441241\n",
            "Epoch 22, Loss: 2.131001820903563\n",
            "Epoch 23, Loss: 2.1287770858816195\n",
            "Epoch 24, Loss: 2.1265576413626035\n",
            "Epoch 25, Loss: 2.1243435101073773\n",
            "Epoch 26, Loss: 2.1221347127486574\n",
            "Epoch 27, Loss: 2.1199312678829147\n",
            "Epoch 28, Loss: 2.1177331921521234\n",
            "Epoch 29, Loss: 2.115540500314856\n",
            "Epoch 30, Loss: 2.113353205308733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = torch.randn((1, NUM_INPUTS))\n",
        "model_nn.eval()\n",
        "\n",
        "exported = torch.export.export(model_nn, (example_input,))\n",
        "torch._inductor.aoti_compile_and_package(\n",
        "    exported,\n",
        "    package_path=\"model_nn.pt2\",\n",
        ")\n",
        "with open(\"model_nn_inputs.txt\", \"w\") as f:\n",
        "    f.write(\n",
        "        f\"{len(example_input.shape)} {' '.join(map(str, example_input.shape))}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "3cIXcaWA1cCk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmake_contents = \"\"\"cmake_minimum_required(VERSION 3.18 FATAL_ERROR)\n",
        "project(aoti_example)\n",
        "\n",
        "find_package(Torch REQUIRED)\n",
        "\n",
        "add_executable(aoti_example inference.cpp)\n",
        "\n",
        "target_link_libraries(aoti_example \"${TORCH_LIBRARIES}\")\n",
        "set_property(TARGET aoti_example PROPERTY CXX_STANDARD 17)\n",
        "\"\"\"\n",
        "with open('CMakeLists.txt', 'w') as f:\n",
        "    f.write(cmake_contents)"
      ],
      "metadata": {
        "id": "DTHMpZyM7mT7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_contents = \"\"\"export CMAKE_PREFIX_PATH=/usr/local/lib/python3.11/dist-packages/torch/share/cmake\n",
        "export TORCHINDUCTOR_FREEZING=1\n",
        "\n",
        "\n",
        "rm -rf build\n",
        "mkdir build\n",
        "cmake -B build .\n",
        "cmake --build build --config Release\n",
        "\"\"\"\n",
        "with open('build.sh', 'w') as f:\n",
        "    f.write(build_contents)"
      ],
      "metadata": {
        "id": "XbFtCu1t79Sx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x ./build.sh"
      ],
      "metadata": {
        "id": "viy_pWo021NY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_content = \"\"\"#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <fstream>\n",
        "\n",
        "#include <torch/torch.h>\n",
        "#include <torch/csrc/inductor/aoti_package/model_package_loader.h>\n",
        "\n",
        "using namespace std::chrono;\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "\n",
        "    if (argc < 3) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" <model.pt2> <inputs.txt>\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Load input\n",
        "    std::ifstream input_file{argv[2]};\n",
        "    if (!input_file) {\n",
        "        std::cerr << \"Error opening input file: \" << argv[2] << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "    int num_dims {};\n",
        "    input_file >> num_dims;\n",
        "\n",
        "    std::vector<int64_t> input_dims{};\n",
        "    for (int i = 0; i < num_dims; ++i) {\n",
        "        int64_t dim_size;\n",
        "        input_file >> dim_size;\n",
        "        input_dims.push_back(dim_size);\n",
        "    }\n",
        "\n",
        "    input_file.close();\n",
        "\n",
        "    // auto arrayRef = c10::makeArrayRef(input_dims);\n",
        "    torch::Tensor input = torch::randn(input_dims, torch::dtype(torch::kFloat64));\n",
        "    std::vector<torch::Tensor> inputs { input };\n",
        "\n",
        "    c10::InferenceMode mode;\n",
        "    torch::inductor::AOTIModelPackageLoader loader(argv[1], \"model\", false);\n",
        "\n",
        "\n",
        "    // std::vector<torch::Tensor> inputs = {torch::randn({1, 2}, torch::dtype(torch::kFloat64))};\n",
        "\n",
        "    // Warmup\n",
        "    std::vector<torch::Tensor> outputs;\n",
        "    for (int i = 0; i < 1000; i++) {\n",
        "        outputs = loader.run(inputs);\n",
        "    }\n",
        "\n",
        "    // Benchmark\n",
        "    auto start_time = std::chrono::high_resolution_clock::now();\n",
        "    for (int i = 0; i < 1000; i++) {\n",
        "        outputs = loader.run(inputs);\n",
        "    }\n",
        "    auto end_time = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    auto elapsed = duration_cast<microseconds>(end_time - start_time);\n",
        "    std::cout << \"Average inference time over 1000 runs: \"\n",
        "              << (elapsed.count() / 1000) << \" us\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with open('inference.cpp', 'w') as f:\n",
        "    f.write(cpp_content)"
      ],
      "metadata": {
        "id": "1kFbKixS8Ixw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ."
      ],
      "metadata": {
        "id": "W-8Z-w542_to",
        "outputId": "5231ca1e-55cb-4a68-acdc-9cc9f9f32e3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build\t  CMakeLists.txt  model_nn_inputs.txt  sample_data\n",
            "build.sh  inference.cpp   model_nn.pt2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./build.sh"
      ],
      "metadata": {
        "id": "iw3MHqnR3C9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa4b764-e828-4f4f-c33d-cdb3ca98209d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[33mCMake Warning at /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22 (message):\n",
            "  static library kineto_LIBRARY-NOTFOUND not found.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:125 (append_torchlib_if_found)\n",
            "  CMakeLists.txt:4 (find_package)\n",
            "\n",
            "\u001b[0m\n",
            "-- Found Torch: /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch.so\n",
            "-- Configuring done (0.4s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/build\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/aoti_example.dir/inference.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable aoti_example\u001b[0m\n",
            "[100%] Built target aoti_example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./build/aoti_example model_nn.pt2 model_nn_inputs.txt"
      ],
      "metadata": {
        "id": "m_w_dKYy9Ai5",
        "outputId": "377151de-a9d1-4f3d-adfe-1eee1d3912a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average inference time over 1000 runs: 12 us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Duk06KFpswEd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}